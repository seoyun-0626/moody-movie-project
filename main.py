import json
import os
import sys
import pickle
import random
import pymysql
import gdown
from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
from flask.json.provider import DefaultJSONProvider
from openai import OpenAI
from dotenv import load_dotenv
from movie_api import get_movies_by_genre, get_movie_rating

# ==========================
# âœ… ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
# ==========================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MODEL_DIR = os.path.join(BASE_DIR, "models")
os.makedirs(MODEL_DIR, exist_ok=True)

# ==========================
# âœ… Google Drive íŒŒì¼ ID ëª©ë¡
# ==========================
drive_files = {
    "emotion_model.pkl": "13tBT7LQe9LpJm2xXz9Bm-oNlOdjjYZV1",
    "emotion_sub_model.pkl": "15UWG9J7n66p3iSD0Xe_ClsDtsacOS94U",
    "sub_models.pkl": "1HzcGogcJZfrSiqqEmXOeOK_yYSKth3Kt",
    "sub_vectorizers.pkl": "1U3H-LsFdL0ObM7urt1rJzY5CzGtIAqdT",
    "vectorizer.pkl": "1qgpEY14xJK8uoVzNQYLAmnbS4Oe2BbMg",
}

# ==========================
# âœ… ëª¨ë¸ ìë™ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜
# ==========================
def ensure_models_downloaded():
    for filename, file_id in drive_files.items():
        file_path = os.path.join(MODEL_DIR, filename)
        if not os.path.exists(file_path):
            print(f"â¬‡ï¸ {filename} ë‹¤ìš´ë¡œë“œ ì¤‘...")
            url = f"https://drive.google.com/uc?id={file_id}"
            gdown.download(url, file_path, quiet=False)
        else:
            print(f"âœ… {filename} ì´ë¯¸ ì¡´ì¬")

# ==========================
# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.env)
# ==========================
env_path = os.path.join(BASE_DIR, ".env")
if os.path.exists(env_path):
    load_dotenv(dotenv_path=env_path)
    print(f"ğŸ“‚ .env ë¡œë“œ ì™„ë£Œ: {env_path}")
else:
    print(f"âš ï¸ .env íŒŒì¼ ì—†ìŒ â€” Railway í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš© ì˜ˆì •")

api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("âŒ OpenAI API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
else:
    print(f"ğŸ”‘ OpenAI Key ë¶ˆëŸ¬ì˜´: {api_key[:10]}...")

client = OpenAI(api_key=api_key)

# ==========================
# âœ… Flask ì„¤ì •
# ==========================
app = Flask(__name__, static_folder="static", template_folder="templates")
CORS(app, resources={r"/*": {"origins": "*"}})
app.config["JSON_AS_ASCII"] = False

class UTF8JSONProvider(DefaultJSONProvider):
    def dumps(self, obj, **kwargs):
        kwargs.setdefault("ensure_ascii", False)
        return json.dumps(obj, **kwargs)
    def loads(self, s, **kwargs):
        return json.loads(s, **kwargs)

app.json = UTF8JSONProvider(app)
sys.stdout.reconfigure(encoding="utf-8")

# ==========================
# âœ… ëª¨ë¸ ë¡œë“œ
# ==========================
try:
    ensure_models_downloaded()
    model = pickle.load(open(os.path.join(MODEL_DIR, "emotion_model.pkl"), "rb"))
    sub_model = pickle.load(open(os.path.join(MODEL_DIR, "emotion_sub_model.pkl"), "rb"))
    vectorizer = pickle.load(open(os.path.join(MODEL_DIR, "vectorizer.pkl"), "rb"))
    sub_vectorizer = pickle.load(open(os.path.join(MODEL_DIR, "sub_vectorizers.pkl"), "rb"))
    print("âœ… ê°ì • ë¶„ì„ ëª¨ë¸ ë° ì„¸ë¶€ê°ì • ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
except Exception as e:
    print(f"âŒ ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    exit()

# ==========================
# âœ… ê°ì • â†’ ì¥ë¥´ ë§¤í•‘
# ==========================
emotion_to_genre = {
    "ë¶„ë…¸": [28, 80, 53, 27, 9648],
    "ë¶ˆì•ˆ": [53, 9648, 18, 878],
    "ìŠ¤íŠ¸ë ˆìŠ¤": [35, 10402, 10751, 16],
    "ìŠ¬í””": [18, 10749, 10751, 99],
    "í–‰ë³µ": [12, 35, 16, 10751, 10402],
    "ì‹¬ì‹¬": [14, 878, 12, 10751],
    "íƒêµ¬": [99, 36, 18, 37],
}

def get_genre_by_emotion(emotion):
    return random.choice(emotion_to_genre.get(emotion, [18]))

# ==========================
# âœ… /emotion ì—”ë“œí¬ì¸íŠ¸
# ==========================
@app.route("/emotion", methods=["POST"])
def emotion_endpoint():
    try:
        data = request.get_json()
        user_input = data.get("emotion", "").strip()
        if not user_input:
            return jsonify({"reply": "ê°ì •ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”"}), 400

        X = vectorizer.transform([user_input])
        predicted_emotion = model.predict(X)[0]

        try:
            X_sub = sub_vectorizer.transform([user_input])
            predicted_sub = sub_model.predict(X_sub)[0]
        except Exception:
            predicted_sub = "ì„¸ë¶€ê°ì • ì—†ìŒ"

        genre_id = get_genre_by_emotion(predicted_emotion)
        movies = get_movies_by_genre(genre_id)

        return jsonify({
            "emotion": predicted_emotion,
            "sub_emotion": predicted_sub,
            "movies": movies
        })
    except Exception as e:
        print("âŒ /emotion ì˜¤ë¥˜:", e)
        return jsonify({"reply": "ì„œë²„ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”"}), 500

# ==========================
# âœ… /chat ì—”ë“œí¬ì¸íŠ¸
# ==========================
conversation_history = []

@app.route("/chat", methods=["POST"])
def chat_turn():
    try:
        data = request.get_json()
        user_msg = data.get("message", "")
        turn = data.get("turn", 1)
        gpt_reply = ""

        if isinstance(turn, str):
            turn_type = "after_recommend" if turn == "after_recommend" else "normal"
        else:
            turn_type = "normal"

        conversation_history.append({"role": "user", "content": user_msg})

        if turn_type == "normal" and turn < 3:
            system_prompt = (
                "ë„ˆëŠ” ê°ì •ìƒë‹´ ì¹œêµ¬ì•¼. "
                "ì‚¬ìš©ìì˜ ë§ì„ ë”°ëœ»í•˜ê²Œ ê³µê°í•˜ë©´ì„œ ì§§ê²Œ ë‹µí•˜ê³ , "
                "ë°˜ë“œì‹œ ë§ˆì§€ë§‰ì— ì§ˆë¬¸ì„ í•˜ë‚˜ ë§ë¶™ì—¬."
            )
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_msg},
                ],
            )
            gpt_reply = response.choices[0].message.content.strip()
            conversation_history.append({"role": "assistant", "content": gpt_reply})
            return jsonify({"reply": gpt_reply, "final": False})

        elif turn_type == "after_recommend":
            followup_prompt = (
                "ë„ˆëŠ” ê°ì • ê¸°ë°˜ ì˜í™” ì¶”ì²œ ì¹œêµ¬ì•¼. "
                "ì´ì „ ëŒ€í™”ì™€ ì¶”ì²œ ì˜í™”ë¥¼ ê¸°ì–µí•˜ê³ , "
                "ì‚¬ìš©ìê°€ 'ì²«ë²ˆì§¸êº¼', 'ì´ê±°' ê°™ì€ í‘œí˜„ì„ í•´ë„ ì´í•´í•´ì•¼ í•´. "
                "í‰ì , ë°°ìš°, ë¶„ìœ„ê¸°ë¥¼ ë¬¼ìœ¼ë©´ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•´ì¤˜."
            )
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": followup_prompt},
                    *conversation_history,
                    {"role": "user", "content": user_msg},
                ],
            )
            gpt_reply = response.choices[0].message.content.strip()
            return jsonify({"reply": gpt_reply})

        # âœ… 3í„´ ì´í›„ ìš”ì•½ + ì¶”ì²œ
        summary_prompt = f"""
        ë‹¤ìŒì€ ì‚¬ìš©ìì™€ ê°ì •ìƒë‹´ ì±—ë´‡ì˜ 3í„´ ëŒ€í™”ì•¼:
        {conversation_history}
        ì‚¬ìš©ìì˜ ê°ì • ìƒíƒœë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì¤˜.
        """
        summary_response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ê°ì •ì„ ë”°ëœ»í•˜ê²Œ ìš”ì•½í•˜ëŠ” ì¹œêµ¬ì•¼."},
                {"role": "user", "content": summary_prompt},
            ],
        )
        summary_text = summary_response.choices[0].message.content.strip()
        print("ğŸ§  ëŒ€í™” ìš”ì•½ë¬¸:", summary_text)

        X = vectorizer.transform([summary_text])
        predicted_emotion = model.predict(X)[0]
        try:
            X_sub = sub_vectorizer.transform([summary_text])
            predicted_sub = sub_model.predict(X_sub)[0]
        except Exception:
            predicted_sub = "ì„¸ë¶€ê°ì • ì—†ìŒ"

        genre_id = get_genre_by_emotion(predicted_emotion)
        movies = get_movies_by_genre(genre_id)

        return jsonify({
            "reply": gpt_reply,
            "summary": summary_text,
            "final": True,
            "emotion": predicted_emotion,
            "sub_emotion": predicted_sub,
            "movies": movies
        })

    except Exception as e:
        print("âŒ /chat ì˜¤ë¥˜:", e)
        return jsonify({"reply": "ì„œë²„ ì˜¤ë¥˜ ë°œìƒ"}), 500

# ==========================
# âœ… HTML ë¼ìš°íŠ¸
# ==========================
@app.route("/")
def home():
    return render_template("index.html")

@app.route("/index.html")
def index_alias():
    return render_template("index.html")

@app.route("/chatbot")
def chatbot_page():
    return render_template("chatbot.html")

# ==========================
# âœ… DB ì—°ê²° ë° í†µê³„ API
# ==========================
def get_connection():
    return pymysql.connect(
        host=os.getenv("MYSQLHOST"),
        user=os.getenv("MYSQLUSER"),
        password=os.getenv("MYSQLPASSWORD"),
        db=os.getenv("MYSQLDATABASE"),
        port=int(os.getenv("MYSQLPORT", 3306)),
        charset="utf8mb4",
        cursorclass=pymysql.cursors.DictCursor,
    )

@app.route("/stats")
def get_stats():
    conn = get_connection()
    cursor = conn.cursor()
    cursor.execute("""
        SELECT rep_emotion, COUNT(*) AS count
        FROM movies_emotions
        GROUP BY rep_emotion
        ORDER BY count DESC;
    """)
    result = cursor.fetchall()
    conn.close()
    return jsonify(result)

@app.route("/top10")
def get_top10_movies():
    conn = get_connection()
    cursor = conn.cursor()
    cursor.execute("""
        SELECT movie, COUNT(*) AS count
        FROM movies_emotions
        GROUP BY movie
        ORDER BY count DESC
        LIMIT 10;
    """)
    result = cursor.fetchall()
    conn.close()
    return jsonify(result)

# ==========================
# âœ… ì„œë²„ ì‹¤í–‰
# ==========================
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=int(os.getenv("PORT", 5000)), debug=False, use_reloader=False)
